{
    "name": "root",
    "gauges": {
        "JoymanBh.Policy.Entropy.mean": {
            "value": 1.1160271167755127,
            "min": 1.1160271167755127,
            "max": 1.164463996887207,
            "count": 14
        },
        "JoymanBh.Policy.Entropy.sum": {
            "value": 11050.900390625,
            "min": 2396.466796875,
            "max": 11635.9755859375,
            "count": 14
        },
        "JoymanBh.Step.mean": {
            "value": 659879.0,
            "min": 529913.0,
            "max": 659879.0,
            "count": 14
        },
        "JoymanBh.Step.sum": {
            "value": 659879.0,
            "min": 529913.0,
            "max": 659879.0,
            "count": 14
        },
        "JoymanBh.Policy.ExtrinsicValueEstimate.mean": {
            "value": -710.2251586914062,
            "min": -778.5444946289062,
            "max": -710.2251586914062,
            "count": 14
        },
        "JoymanBh.Policy.ExtrinsicValueEstimate.sum": {
            "value": -88067.921875,
            "min": -110886.03125,
            "max": -21020.701171875,
            "count": 14
        },
        "JoymanBh.Policy.CuriosityValueEstimate.mean": {
            "value": 0.5819990634918213,
            "min": 0.5819990634918213,
            "max": 1.8900423049926758,
            "count": 14
        },
        "JoymanBh.Policy.CuriosityValueEstimate.sum": {
            "value": 72.16788482666016,
            "min": 51.03114318847656,
            "max": 252.2217254638672,
            "count": 14
        },
        "JoymanBh.Environment.EpisodeLength.mean": {
            "value": 121.37037037037037,
            "min": 121.37037037037037,
            "max": 128.85714285714286,
            "count": 14
        },
        "JoymanBh.Environment.EpisodeLength.sum": {
            "value": 9831.0,
            "min": 1804.0,
            "max": 10192.0,
            "count": 14
        },
        "JoymanBh.Environment.CumulativeReward.mean": {
            "value": -1000.0,
            "min": -1000.0,
            "max": -1000.0,
            "count": 14
        },
        "JoymanBh.Environment.CumulativeReward.sum": {
            "value": -81000.0,
            "min": -81000.0,
            "max": -14000.0,
            "count": 14
        },
        "JoymanBh.Policy.ExtrinsicReward.mean": {
            "value": -1000.0,
            "min": -1000.0,
            "max": -1000.0,
            "count": 14
        },
        "JoymanBh.Policy.ExtrinsicReward.sum": {
            "value": -81000.0,
            "min": -81000.0,
            "max": -14000.0,
            "count": 14
        },
        "JoymanBh.Policy.CuriosityReward.mean": {
            "value": 0.0027589220576486203,
            "min": 0.0,
            "max": 0.0027589220576486203,
            "count": 14
        },
        "JoymanBh.Policy.CuriosityReward.sum": {
            "value": 0.22347268666953823,
            "min": 0.0,
            "max": 0.22347268666953823,
            "count": 14
        },
        "JoymanBh.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 14
        },
        "JoymanBh.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 14
        },
        "GluemanBh.Policy.Entropy.mean": {
            "value": 0.7947990298271179,
            "min": 0.7935110926628113,
            "max": 0.9199656844139099,
            "count": 13
        },
        "GluemanBh.Policy.Entropy.sum": {
            "value": 8022.70166015625,
            "min": 7804.98876953125,
            "max": 9136.4267578125,
            "count": 13
        },
        "GluemanBh.Step.mean": {
            "value": 669999.0,
            "min": 549912.0,
            "max": 669999.0,
            "count": 13
        },
        "GluemanBh.Step.sum": {
            "value": 669999.0,
            "min": 549912.0,
            "max": 669999.0,
            "count": 13
        },
        "GluemanBh.Policy.ExtrinsicValueEstimate.mean": {
            "value": -184.9368438720703,
            "min": -187.49517822265625,
            "max": -149.70973205566406,
            "count": 13
        },
        "GluemanBh.Policy.ExtrinsicValueEstimate.sum": {
            "value": -15164.8212890625,
            "min": -15944.6005859375,
            "max": -12425.9072265625,
            "count": 13
        },
        "GluemanBh.Policy.CuriosityValueEstimate.mean": {
            "value": 0.05577222257852554,
            "min": 0.03845997899770737,
            "max": 0.45540568232536316,
            "count": 13
        },
        "GluemanBh.Policy.CuriosityValueEstimate.sum": {
            "value": 4.573322296142578,
            "min": 3.192178249359131,
            "max": 38.25407791137695,
            "count": 13
        },
        "GluemanBh.Environment.EpisodeLength.mean": {
            "value": 1105.7,
            "min": 789.5384615384615,
            "max": 1105.7,
            "count": 13
        },
        "GluemanBh.Environment.EpisodeLength.sum": {
            "value": 11057.0,
            "min": 6868.0,
            "max": 11415.0,
            "count": 13
        },
        "GluemanBh.Environment.CumulativeReward.mean": {
            "value": -981.0,
            "min": -994.1666666666666,
            "max": -977.2727272727273,
            "count": 13
        },
        "GluemanBh.Environment.CumulativeReward.sum": {
            "value": -9810.0,
            "min": -13760.0,
            "max": -7940.0,
            "count": 13
        },
        "GluemanBh.Policy.ExtrinsicReward.mean": {
            "value": -981.0,
            "min": -994.1666666666666,
            "max": -977.2727272727273,
            "count": 13
        },
        "GluemanBh.Policy.ExtrinsicReward.sum": {
            "value": -9810.0,
            "min": -13760.0,
            "max": -7940.0,
            "count": 13
        },
        "GluemanBh.Policy.CuriosityReward.mean": {
            "value": 3.9991886090717795e-06,
            "min": 2.0812574590597008e-07,
            "max": 0.012825663437255663,
            "count": 13
        },
        "GluemanBh.Policy.CuriosityReward.sum": {
            "value": 3.99918860907178e-05,
            "min": 2.497508950871641e-06,
            "max": 0.1026053074980453,
            "count": 13
        },
        "GluemanBh.Losses.PolicyLoss.mean": {
            "value": 0.06818012076171338,
            "min": 0.06581422422295873,
            "max": 0.070197999454723,
            "count": 13
        },
        "GluemanBh.Losses.PolicyLoss.sum": {
            "value": 0.3409006038085669,
            "min": 0.19787847730685826,
            "max": 0.350989997273615,
            "count": 13
        },
        "GluemanBh.Losses.ValueLoss.mean": {
            "value": 73.58058732980314,
            "min": 21.59304240606725,
            "max": 99.85359981432558,
            "count": 13
        },
        "GluemanBh.Losses.ValueLoss.sum": {
            "value": 367.9029366490157,
            "min": 103.06998643837869,
            "max": 499.26799907162786,
            "count": 13
        },
        "GluemanBh.Policy.LearningRate.mean": {
            "value": 0.00029003459132180396,
            "min": 0.00029003459132180396,
            "max": 0.00029181217772927495,
            "count": 13
        },
        "GluemanBh.Policy.LearningRate.sum": {
            "value": 0.0014501729566090199,
            "min": 0.0008754365331878249,
            "max": 0.0014584326588557846,
            "count": 13
        },
        "GluemanBh.Policy.Epsilon.mean": {
            "value": 0.196678196,
            "min": 0.196678196,
            "max": 0.19727072499999998,
            "count": 13
        },
        "GluemanBh.Policy.Epsilon.sum": {
            "value": 0.98339098,
            "min": 0.5918121749999999,
            "max": 0.9861442149999999,
            "count": 13
        },
        "GluemanBh.Policy.Beta.mean": {
            "value": 0.0005000000000000002,
            "min": 0.0005000000000000002,
            "max": 0.0005000000000000002,
            "count": 13
        },
        "GluemanBh.Policy.Beta.sum": {
            "value": 0.0025000000000000014,
            "min": 0.0015000000000000007,
            "max": 0.0025000000000000014,
            "count": 13
        },
        "GluemanBh.Losses.CuriosityForwardLoss.mean": {
            "value": 1.425212203371864e-07,
            "min": 1.2101023752486562e-08,
            "max": 0.00012403007494863477,
            "count": 13
        },
        "GluemanBh.Losses.CuriosityForwardLoss.sum": {
            "value": 7.126061016859321e-07,
            "min": 6.050511876243281e-08,
            "max": 0.0003720902248459043,
            "count": 13
        },
        "GluemanBh.Losses.CuriosityInverseLoss.mean": {
            "value": 0.8743540584438426,
            "min": 0.8665009804535657,
            "max": 1.1420542245420318,
            "count": 13
        },
        "GluemanBh.Losses.CuriosityInverseLoss.sum": {
            "value": 4.371770292219213,
            "min": 3.426162673626095,
            "max": 5.563260602299124,
            "count": 13
        },
        "GluemanBh.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 13
        },
        "GluemanBh.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 13
        },
        "JoymanBh.Losses.PolicyLoss.mean": {
            "value": 0.06734312850346669,
            "min": 0.06297847307696429,
            "max": 0.07240379175100316,
            "count": 13
        },
        "JoymanBh.Losses.PolicyLoss.sum": {
            "value": 0.26937251401386675,
            "min": 0.26522896032349763,
            "max": 0.3620189587550158,
            "count": 13
        },
        "JoymanBh.Losses.ValueLoss.mean": {
            "value": 287.76118464767933,
            "min": 134.14882667958736,
            "max": 493.5507494658232,
            "count": 13
        },
        "JoymanBh.Losses.ValueLoss.sum": {
            "value": 1151.0447385907173,
            "min": 670.7441333979368,
            "max": 2409.136139035225,
            "count": 13
        },
        "JoymanBh.Policy.LearningRate.mean": {
            "value": 0.00029017485327505,
            "min": 0.00029017485327505,
            "max": 0.000291985649671451,
            "count": 13
        },
        "JoymanBh.Policy.LearningRate.sum": {
            "value": 0.0011606994131002,
            "min": 0.0011606994131002,
            "max": 0.001459928248357255,
            "count": 13
        },
        "JoymanBh.Policy.Epsilon.mean": {
            "value": 0.19672495,
            "min": 0.19672495,
            "max": 0.197328549,
            "count": 13
        },
        "JoymanBh.Policy.Epsilon.sum": {
            "value": 0.7868998,
            "min": 0.7868998,
            "max": 0.9866427449999999,
            "count": 13
        },
        "JoymanBh.Policy.Beta.mean": {
            "value": 0.0005000000000000002,
            "min": 0.0005000000000000002,
            "max": 0.0005000000000000002,
            "count": 13
        },
        "JoymanBh.Policy.Beta.sum": {
            "value": 0.002000000000000001,
            "min": 0.002000000000000001,
            "max": 0.0025000000000000014,
            "count": 13
        },
        "JoymanBh.Losses.CuriosityForwardLoss.mean": {
            "value": 0.0013094988186139744,
            "min": 0.0007686193013114462,
            "max": 0.0013094988186139744,
            "count": 13
        },
        "JoymanBh.Losses.CuriosityForwardLoss.sum": {
            "value": 0.005237995274455898,
            "min": 0.0030744772052457847,
            "max": 0.006054743361801229,
            "count": 13
        },
        "JoymanBh.Losses.CuriosityInverseLoss.mean": {
            "value": 2.5886380614247173,
            "min": 2.5141550548374654,
            "max": 2.8046177726238968,
            "count": 13
        },
        "JoymanBh.Losses.CuriosityInverseLoss.sum": {
            "value": 10.35455224569887,
            "min": 10.35455224569887,
            "max": 14.023088863119483,
            "count": 13
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1691954857",
        "python_version": "3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0]",
        "command_line_arguments": "/home/doiry/anaconda3/envs/aml/bin/mlagents-learn config/Glue-Joy-War.yaml --run-id=Test --torch-device=cuda --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0+cu113",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1691956365"
    },
    "total": 1508.8479034369993,
    "count": 1,
    "self": 0.0038099199991847854,
    "children": {
        "run_training.setup": {
            "total": 0.025214060999132926,
            "count": 1,
            "self": 0.025214060999132926
        },
        "TrainerController.start_learning": {
            "total": 1508.818879456001,
            "count": 1,
            "self": 0.7062042098223174,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.245191044999956,
                    "count": 1,
                    "self": 6.245191044999956
                },
                "TrainerController.advance": {
                    "total": 1501.799900798178,
                    "count": 67201,
                    "self": 0.7730508813692722,
                    "children": {
                        "env_step": {
                            "total": 1342.7404680663167,
                            "count": 67201,
                            "self": 1275.4406116370737,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 66.85030325897606,
                                    "count": 67201,
                                    "self": 4.4140761923881655,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 62.43622706658789,
                                            "count": 132168,
                                            "self": 62.43622706658789
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.44955317026688135,
                                    "count": 67200,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1504.0250268251693,
                                            "count": 67200,
                                            "is_parallel": true,
                                            "self": 274.04552957011765,
                                            "children": {
                                                "run_training.setup": {
                                                    "total": 0.0,
                                                    "count": 0,
                                                    "is_parallel": true,
                                                    "self": 0.0,
                                                    "children": {
                                                        "steps_from_proto": {
                                                            "total": 0.0004895130041404627,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0001265499959117733,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.00036296300822868943,
                                                                    "count": 8,
                                                                    "is_parallel": true,
                                                                    "self": 0.00036296300822868943
                                                                }
                                                            }
                                                        },
                                                        "UnityEnvironment.step": {
                                                            "total": 0.012535753998236032,
                                                            "count": 1,
                                                            "is_parallel": true,
                                                            "self": 0.00010790300075314008,
                                                            "children": {
                                                                "UnityEnvironment._generate_step_input": {
                                                                    "total": 0.00013274699813337065,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.00013274699813337065
                                                                },
                                                                "communicator.exchange": {
                                                                    "total": 0.011848376998386811,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.011848376998386811
                                                                },
                                                                "steps_from_proto": {
                                                                    "total": 0.00044672700096271,
                                                                    "count": 2,
                                                                    "is_parallel": true,
                                                                    "self": 0.00018736300262389705,
                                                                    "children": {
                                                                        "_process_rank_one_or_two_observation": {
                                                                            "total": 0.00025936399833881296,
                                                                            "count": 8,
                                                                            "is_parallel": true,
                                                                            "self": 0.00025936399833881296
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1229.9794972550517,
                                                    "count": 67199,
                                                    "is_parallel": true,
                                                    "self": 4.435122240833152,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 3.2577902090088173,
                                                            "count": 67199,
                                                            "is_parallel": true,
                                                            "self": 3.2577902090088173
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1207.1837866961105,
                                                            "count": 67199,
                                                            "is_parallel": true,
                                                            "self": 1207.1837866961105
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 15.10279810909924,
                                                            "count": 134398,
                                                            "is_parallel": true,
                                                            "self": 5.695680219305359,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 9.40711788979388,
                                                                    "count": 537592,
                                                                    "is_parallel": true,
                                                                    "self": 9.40711788979388
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 158.28638185049203,
                            "count": 134400,
                            "self": 1.1355899087175203,
                            "children": {
                                "process_trajectory": {
                                    "total": 11.50848757978747,
                                    "count": 134400,
                                    "self": 11.50848757978747
                                },
                                "_update_policy": {
                                    "total": 145.64230436198704,
                                    "count": 125,
                                    "self": 99.98180608182156,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 45.660498280165484,
                                            "count": 16016,
                                            "self": 45.660498280165484
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.180016498547047e-07,
                    "count": 1,
                    "self": 6.180016498547047e-07
                },
                "TrainerController._save_models": {
                    "total": 0.06758278499910375,
                    "count": 1,
                    "self": 0.0007821010040061083,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.06680068399509764,
                            "count": 2,
                            "self": 0.06680068399509764
                        }
                    }
                }
            }
        }
    }
}